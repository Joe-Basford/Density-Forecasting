{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f1e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#######################################################################\n",
    "######################### Importing Packages ##########################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "# plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# numpy and pandas\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "from numpy import ix_\n",
    "import pandas as pd\n",
    "\n",
    "# miscellany to make code neater\n",
    "from typing import Callable\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# some basic statistical/numerical scipy parts used to calculate scores\n",
    "import scipy.stats\n",
    "import scipy.integrate as integrate\n",
    "import scipy.special as special\n",
    "\n",
    "# Tensorflow and Keras parts which are used for data processing and model creation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# tensorflow pdf calculator which is used to calculate losses efficiently\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# setting seed as stochastic intialisation\n",
    "tf.random.set_seed(11)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646da74d",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"C:/Warwick Final Year/RAE/\"\n",
    "raw_path = main_path + \"Data/\"\n",
    "processed_path = main_path + \"Processed Data/\"\n",
    "graphs_path = main_path + \"Graphs/\"\n",
    "arma_garch_graphs_path = graphs_path + \"ARMA_GARCH_Graphs/\"\n",
    "checkpoints_path = main_path + \"Code Python/Model Checkpoints/\"\n",
    "\n",
    "\n",
    "ARMA_GARCH = defaultdict(dict)\n",
    "\n",
    "for which_series in ['DAX','NASDAQ','Nikkei']:\n",
    "    for filename in os.listdir(processed_path + which_series +'/ARMA_GARCH'):\n",
    "            if filename.endswith('.csv'):\n",
    "                ARMA_GARCH[which_series][filename[:-4 or None]] = pd.read_csv(processed_path  \n",
    "                                                                              + which_series \n",
    "                                                                              + '/ARMA_GARCH/' \n",
    "                                                                              + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#######################################################################\n",
    "###################### Data Importing/Cleaning ########################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "# import data and calculate log returns from adjusted close\n",
    "df_Nikkei_RAW = pd.read_csv(raw_path + \"/^N225.csv\")\n",
    "df_NASDAQ_RAW = pd.read_csv(raw_path + \"^IXIC.csv\")\n",
    "df_DAX_RAW = pd.read_csv(raw_path + \"^GDAXI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Processor(DATA: pd.DataFrame,\n",
    "                   batch_size: int,\n",
    "                   length_sample: int,\n",
    "                   test_train_split: str) -> dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    Processes data to a usable form. Splits data into a training and test set based on date\n",
    "    given by 'test_train_split'. Makes data automatically batch and use a lag length of 'length_sample'.\n",
    "    \n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    @param DATA: pd.DataFrame, stock index data from Yahoo Finance with Adjusted Closing prices and Date as columns\n",
    "    @param batch_size: int, size of batch used whilst training models\n",
    "    @param length_sample: int, number of lagged trading days to use whilst forecasting each timestep\n",
    "    @param test_train_split: str, date at which to split data for training and validation - format of \"dd-mm-yyyy\"\n",
    "    \n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \n",
    "    @return: dict, dictionary with 3 keys. DATA key is the log return data for the given series after cleaning\n",
    "                                           Training key is the training data which is batched and has given sample size\n",
    "                                           Validation key is the validation data which is batch and has given sample size\n",
    "    \n",
    "    #################################################################################################################\n",
    "    #################################################################################################################\n",
    "    \"\"\"\n",
    "    \n",
    "    DATA.columns = [c.replace(' ', '_') for c in DATA.columns]\n",
    "    DATA = DATA[DATA['Adj_Close'].notnull()]\n",
    "    DATA['log_ret'] = np.log(DATA.Adj_Close) - np.log(DATA.Adj_Close.shift(1))\n",
    "\n",
    "    # spilt to training and test sets\n",
    "    DATA    = DATA[['Date', 'log_ret']][1:]\n",
    "    DATA['Date'] = DATA['Date'].apply(pd.Timestamp)\n",
    "    DATA.set_index('Date', inplace=True, drop=True)\n",
    "    \n",
    "    train = DATA.loc[:test_train_split]\n",
    "    test  = DATA.loc[test_train_split:]\n",
    "   \n",
    "    DATA_train = [[i] for i in train['log_ret']]\n",
    "    DATA_test  = [[i] for i in test['log_ret']]\n",
    "    \n",
    "    time_series_generator = TimeseriesGenerator(DATA_train, \n",
    "                                                DATA_train, \n",
    "                                                length = length_sample, \n",
    "                                                batch_size = batch_size)\n",
    "    time_series_val_generator = TimeseriesGenerator(DATA_test,\n",
    "                                                    DATA_test, \n",
    "                                                    length = length_sample, \n",
    "                                                    batch_size = batch_size)\n",
    "\n",
    "    \n",
    "    return {\"Data\": DATA,\n",
    "            \"Training\": time_series_generator,\n",
    "            \"Validation\": time_series_val_generator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce886ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_Size = 64\n",
    "Length = 10\n",
    "Test_Train_Split = '2015-01-01'\n",
    "\n",
    "\n",
    "\n",
    "Nikkei = Data_Processor(df_Nikkei_RAW,\n",
    "                       Batch_Size,\n",
    "                       Length,\n",
    "                       Test_Train_Split)\n",
    "NASDAQ = Data_Processor(df_NASDAQ_RAW,\n",
    "                       Batch_Size,\n",
    "                       Length,\n",
    "                       Test_Train_Split)\n",
    "DAX = Data_Processor(df_DAX_RAW,\n",
    "                       Batch_Size,\n",
    "                       Length,\n",
    "                       Test_Train_Split)\n",
    "\n",
    "\n",
    "DATA = {'Nikkei': Nikkei,\n",
    "        'NASDAQ': NASDAQ,\n",
    "        'DAX': DAX}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for which_series in ['DAX','NASDAQ','Nikkei']:\n",
    "    for k in ARMA_GARCH[which_series].keys():\n",
    "        \n",
    "    \n",
    "        means = ARMA_GARCH[which_series][k]['Norm_mu']\n",
    "        scale   = ARMA_GARCH[which_series][k]['Norm_std']\n",
    "\n",
    "        x = pd.date_range(\"2015-01-01\", periods=len(means),freq=\"D\")\n",
    "\n",
    "\n",
    "        plt.plot(x,DATA[which_series]['Data'].loc['2015-01-01':]['log_ret'], color='#1f77b4',zorder=1)\n",
    "\n",
    "        ppf = scipy.stats.norm.ppf\n",
    "\n",
    "        SCORE = round(np.sum(np.log(scipy.stats.norm.pdf(DATA[which_series]['Data'].loc['2015-01-01':]['log_ret'],\n",
    "                                                 loc = means,\n",
    "                                                 scale = scale)))/len(DATA[which_series]['Data'].loc['2015-01-01':]['log_ret']),4)\n",
    "        NAME = \"Normal\"\n",
    "\n",
    "        s1 = plt.fill_between(x, np.add(means,ppf(0.95, loc = means, scale = scale)),\n",
    "                              np.add(means, ppf(0.05, loc = means, scale = scale)), \n",
    "                              color = 'green', zorder = 4, alpha = 0.4)\n",
    "        s2 = plt.fill_between(x, np.add(means, ppf(0.975, loc = means, scale = scale)),\n",
    "                         np.add(means, ppf(0.025, loc = means, scale = scale)), \n",
    "                         color = 'grey',\n",
    "                             zorder = 3,\n",
    "                             alpha = 0.5)\n",
    "        plt.plot(x, means, color = 'black', zorder = 2)\n",
    "\n",
    "        plt.title(NAME)\n",
    "\n",
    "        plt.text(pd.to_datetime('2019-06-01'), \n",
    "                -0.08,\n",
    "                \"SCORE=\" + str(SCORE),\n",
    "                horizontalalignment = 'center', \n",
    "                fontweight = 'bold', \n",
    "                color = 'red',\n",
    "                fontsize = 'medium')\n",
    "\n",
    "        years = mdates.YearLocator(10)  \n",
    "        years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "\n",
    "        #plt.xaxis.set_major_locator(years)\n",
    "        #plt.xaxis.set_major_formatter(years_fmt)\n",
    "        plt.ylabel(\"Log Returns\")\n",
    "        plt.legend(handles = [s1, s2], labels = [\"10%\", \"5%\"], loc = 'upper right')\n",
    "        plt.ylim([-0.15, 0.15])\n",
    "        plt.tight_layout() \n",
    "\n",
    "        plt.savefig(arma_garch_graphs\n",
    "                    + which_series \n",
    "                    + '_' \n",
    "                    + k \n",
    "                    +  '_' \n",
    "                    + 'Normal'  \n",
    "                    + '.pdf')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ee391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next the Laplace\n",
    "for which_series in ['DAX','NASDAQ','Nikkei']:\n",
    "    for k in ARMA_GARCH[which_series].keys():\n",
    "        \n",
    "    \n",
    "        means = ARMA_GARCH[which_series][k]['Lap_mu']\n",
    "        scale   = ARMA_GARCH[which_series][k]['Lap_std']/2\n",
    "\n",
    "        x = pd.date_range(\"2015-01-01\", periods = len(means), freq = \"D\")\n",
    "\n",
    "\n",
    "        plt.plot(x, DATA[which_series]['Data'].loc['2015-01-01':]['log_ret'], color = '#1f77b4', zorder = 1)\n",
    "\n",
    "        ppf = scipy.stats.laplace.ppf\n",
    "\n",
    "        SCORE = round(np.sum(np.log(scipy.stats.laplace.pdf(DATA[which_series]['Data'].loc['2015-01-01':]['log_ret'],\n",
    "                                                 loc = means,\n",
    "                                                 scale = scale)))/len(DATA[which_series]['Data'].loc['2015-01-01':]['log_ret']),4)\n",
    "        NAME = \"Laplace\"\n",
    "\n",
    "        s1 = plt.fill_between(x, np.add(means, ppf(0.95, loc = means, scale = scale)),\n",
    "                              np.add(means, ppf(0.05, loc = means, scale = scale)), \n",
    "                              color = 'green', zorder = 4, alpha = 0.4)\n",
    "        s2 = plt.fill_between(x, np.add(means,ppf(0.975, loc = means, scale = scale)),\n",
    "                              np.add(means, ppf(0.025, loc = means, scale = scale)), \n",
    "                              color = 'grey',\n",
    "                              zorder = 3,\n",
    "                              alpha = 0.5)\n",
    "        plt.plot(x ,means, color = 'black', zorder = 2)\n",
    "\n",
    "        plt.title(NAME)\n",
    "\n",
    "        plt.text(pd.to_datetime('2019-06-01'), \n",
    "                -0.08,\n",
    "                \"SCORE=\" + str(SCORE),\n",
    "                horizontalalignment = 'center', \n",
    "                fontweight = 'bold', \n",
    "                color = 'red',\n",
    "                fontsize = 'medium')\n",
    "\n",
    "        years = mdates.YearLocator(10)   \n",
    "        years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "        plt.ylabel(\"Log Returns\")\n",
    "        plt.legend(handles = [s1, s2], labels = [\"10%\", \"5%\"], loc = 'upper right')\n",
    "        plt.ylim([-0.15, 0.15])\n",
    "        plt.tight_layout() \n",
    "\n",
    "        plt.savefig(arma_garch_graphs  \n",
    "                    + which_series \n",
    "                    + \"_\" \n",
    "                    + k \n",
    "                    +  \"_\" \n",
    "                    + 'Laplace' \n",
    "                    + '.pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally the T\n",
    "for which_series in ['DAX','NASDAQ','Nikkei']:\n",
    "    for k in ARMA_GARCH[which_series].keys():\n",
    "        \n",
    "    \n",
    "        shape = ARMA_GARCH[which_series][k]['T_shape'] \n",
    "\n",
    "        means = ARMA_GARCH[which_series][k]['T_mu']\n",
    "\n",
    "        scale   = np.divide(ARMA_GARCH[which_series][k]['T_std'], np.sqrt(np.divide(shape, (shape-2))))\n",
    "\n",
    "        x = pd.date_range(\"2015-01-01\", periods = len(means), freq = \"D\")\n",
    "\n",
    "\n",
    "        plt.plot(x,DATA[which_series]['Data'].loc['2015-01-01':]['log_ret'], color = '#1f77b4', zorder = 1)\n",
    "\n",
    "        ppf = scipy.stats.t.ppf\n",
    "\n",
    "        SCORE = round(np.sum(np.log(scipy.stats.t.pdf(DATA[which_series]['Data'].loc['2015-01-01':]['log_ret'],\n",
    "                                                 loc = means,\n",
    "                                                 scale = scale,\n",
    "                                                 df = shape)))/len(DATA[which_series]['Data'].loc['2015-01-01':]['log_ret']),4)\n",
    "        NAME = \"Student_T\"\n",
    "\n",
    "        s1 = plt.fill_between(x, np.add(means, ppf(0.95, loc = means, scale = scale, df = shape)),\n",
    "                              np.add(means, ppf(0.05, loc = means, scale = scale, df = shape)), \n",
    "                              color = 'green', zorder = 4, alpha = 0.4)\n",
    "        s2 = plt.fill_between(x,np.add(means, ppf(0.975, loc = means, scale = scale, df = shape)),\n",
    "                         np.add(means, ppf(0.025, loc = means, scale = scale, df = shape)), \n",
    "                         color = 'grey',\n",
    "                             zorder = 3,\n",
    "                             alpha = 0.5)\n",
    "        plt.plot(x, means, color = 'black', zorder = 2)\n",
    "\n",
    "        plt.title(NAME)\n",
    "\n",
    "        plt.text(pd.to_datetime('2019-06-01'), \n",
    "                -0.08,\n",
    "                \"SCORE=\" + str(SCORE),\n",
    "                horizontalalignment = 'center', \n",
    "                fontweight = 'bold', \n",
    "                color = 'red',\n",
    "                fontsize = 'medium')\n",
    "\n",
    "        years = mdates.YearLocator(10)  \n",
    "        years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "\n",
    "\n",
    "        plt.ylabel(\"Log Returns\")\n",
    "        plt.legend(handles = [s1,s2], labels = [\"10%\",\"5%\"], loc = 'upper right')\n",
    "        plt.ylim([-0.15, 0.15])\n",
    "        plt.tight_layout() \n",
    "\n",
    "        plt.savefig(arma_garch_graphs  \n",
    "                    + which_series \n",
    "                    + \"_\" \n",
    "                    + k \n",
    "                    +  \"_\" \n",
    "                    + 'T'  \n",
    "                    + '.pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf54c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
